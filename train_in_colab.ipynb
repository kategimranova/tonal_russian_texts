{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_in_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RidFZYgMlIPD",
        "colab_type": "text"
      },
      "source": [
        "Загрузка файла ./dataset/positive.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCx4N-fblBEX",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b5ffd2ba-5ffc-4bc6-e371-795f02f9f557"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_pos = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4856d70e-27ea-4779-aec4-f7b4ea9b7487\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4856d70e-27ea-4779-aec4-f7b4ea9b7487\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving positive100.csv to positive100.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjAwSdXUlQ9w",
        "colab_type": "text"
      },
      "source": [
        "Загрузка файла ./dataset/negative.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-XSIvZ-lRuf",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4b1e273e-07c9-4926-e0c7-077e72c2cb74"
      },
      "source": [
        "uploaded_neg = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d31a324c-edb5-45b5-8357-cd45b3149336\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d31a324c-edb5-45b5-8357-cd45b3149336\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving negative100.csv to negative100.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Uocn-fwnye-",
        "colab_type": "text"
      },
      "source": [
        "### Импорт необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "912I5pQOb4TA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "78c07659-15f3-490a-dc2b-2e6cefa37156"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import Counter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wX3p4k0A7QY",
        "colab_type": "text"
      },
      "source": [
        "### Считывание данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOfgUTRObyXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
        "data_positive = pd.read_csv('positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
        "data_negative = pd.read_csv('negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4OKkcDAA3JR",
        "colab_type": "text"
      },
      "source": [
        "### Формирование сбалансированного датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuFziKescpdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_size = 40000\n",
        "reviews_withoutshuffle = np.concatenate((data_positive['text'].values[:sample_size],\n",
        "                           data_negative['text'].values[:sample_size]), axis=0)\n",
        "labels_withoutshuffle = np.asarray([1] * sample_size + [0] * sample_size)\n",
        "\n",
        "assert len(reviews_withoutshuffle) == len(labels_withoutshuffle)\n",
        "from sklearn.utils import shuffle\n",
        "reviews,labels = shuffle(reviews_withoutshuffle, labels_withoutshuffle, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teyJYXuMqnKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfc80dfe-c806-464c-9c8f-3041d67ab704"
      },
      "source": [
        "print(reviews[100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@Nazirochka03 у меня всееегда так :D я не смотрю в глаза называя цифры\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odsDQSD6Fwse",
        "colab_type": "text"
      },
      "source": [
        "### Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbg32M69b3Zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize():\n",
        "  punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
        "  all_reviews = 'separator'.join(reviews)\n",
        "  all_reviews = all_reviews.lower()\n",
        "  all_text = ''.join([c for c in all_reviews if c not in punctuation])\n",
        "  texts_split = all_text.split('separator')\n",
        "  all_text = ' '.join(texts_split)\n",
        "  words = all_text.split()\n",
        "  return words, texts_split\n",
        "\n",
        "words, texts_split = tokenize()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI5a5m7IekFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_reviews = []\n",
        "for review in texts_split:\n",
        "    review = review.split()\n",
        "    new_text = []\n",
        "    for word in review:\n",
        "        if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n",
        "            new_text.append(word)\n",
        "    new_reviews.append(new_text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4u0eUxPevHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii - 1 for ii, word in enumerate(vocab, 1)}\n",
        "reviews_ints = []\n",
        "for review in new_reviews:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review])\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyQIhUcWf0MI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_pads(reviews_ints, seq_length):\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        if len(row) == 0:\n",
        "            continue\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    return features"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbKei28Ymt7U",
        "colab_type": "text"
      },
      "source": [
        "### Разделение на обучающую, валидационную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJIHlPHYgFeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = add_pads(reviews_ints, seq_length=30)\n",
        "split_frac = 0.8 # 80% на обучающую выборку\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = labels[:split_idx], labels[split_idx:]\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "batch_size = 50\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lK3HUhBcoDgy",
        "colab_type": "text"
      },
      "source": [
        "### Определение режима: GPU или CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTZURLbfGk9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "943729c7-d411-46b4-9d30-8a4ded584895"
      },
      "source": [
        "train_gpu=torch.cuda.is_available()\n",
        "\n",
        "print(train_gpu)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YVn6qEcoLov",
        "colab_type": "text"
      },
      "source": [
        "### Архитектура нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMGb4xZTi_h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM_architecture(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, number_of_layers, drop=0.5):\n",
        "        super(LSTM_architecture, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.number_of_layers = number_of_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, number_of_layers,dropout=drop, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.45)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        lstm_out, hidden_state = self.lstm(self.embedding(x.long()), hidden_state)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        sig_out = self.sigmoid(out)\n",
        "        batch_size = x.size(0)\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1]\n",
        "        return sig_out, hidden_state\n",
        "\n",
        "    def init_hidden_state(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden_state = (weight.new(self.number_of_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.number_of_layers, batch_size, self.hidden_dim).zero_())\n",
        "        return hidden_state\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d22xLEVf9kw",
        "colab_type": "text"
      },
      "source": [
        "###Выбор гиперпараметров и инициализация сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8ceq4OjFW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab_to_int)+1\n",
        "output_size = 1\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "model = LSTM_architecture(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty7J6NXZhn-N",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXTBYHCcjHy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "2cf37b27-4cd0-4d8e-e7a5-a5da63bdd658"
      },
      "source": [
        "epochs = 4 #оптимальное количество эпох для того, чтобы модель достаточно обучилась, но не переобучилась\n",
        "counter = 0\n",
        "batch_num = 100\n",
        "clip=5 \n",
        "if(train_gpu):\n",
        "    model.cuda()\n",
        "num_correct = 0\n",
        "model.train()\n",
        "for e in range(epochs):\n",
        "    h = model.init_hidden_state(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "        num_correct = 0\n",
        "        counter += 1\n",
        "        if(train_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        h = tuple([each.data for each in h])\n",
        "        model.zero_grad()\n",
        "        output, h = model.forward(inputs, h)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        if counter % batch_num == 0:\n",
        "            val_h = model.init_hidden_state(batch_size)\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                if(train_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "                output, val_h = model(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "                #accuracy\n",
        "                pred = torch.round(output.squeeze()) \n",
        "                correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "                correct = np.squeeze(correct_tensor.numpy()) if not train_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "                num_correct += np.sum(correct)\n",
        "                valid_acc = num_correct/len(valid_loader.dataset)\n",
        "\n",
        "            model.train()\n",
        "            print(\"Epoch: {} ;\".format(e+1),\n",
        "                  \"Batch Number: {};\".format(counter),\n",
        "                  \"Train Loss: {:.4f} ;\".format(loss.item()),\n",
        "                  \"Valid Loss: {:.4f} ;\".format(np.mean(val_losses)),\n",
        "                  \"Valid Accuracy: {:.4f}\".format(valid_acc))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 ; Batch Number: 100; Train Loss: 0.7056 ; Valid Loss: 0.6774 ; Valid Accuracy: 0.5734\n",
            "Epoch: 1 ; Batch Number: 200; Train Loss: 0.6054 ; Valid Loss: 0.6379 ; Valid Accuracy: 0.6111\n",
            "Epoch: 1 ; Batch Number: 300; Train Loss: 0.5916 ; Valid Loss: 0.6249 ; Valid Accuracy: 0.6388\n",
            "Epoch: 1 ; Batch Number: 400; Train Loss: 0.6366 ; Valid Loss: 0.6163 ; Valid Accuracy: 0.6460\n",
            "Epoch: 1 ; Batch Number: 500; Train Loss: 0.5793 ; Valid Loss: 0.6130 ; Valid Accuracy: 0.6526\n",
            "Epoch: 1 ; Batch Number: 600; Train Loss: 0.6658 ; Valid Loss: 0.5995 ; Valid Accuracy: 0.6594\n",
            "Epoch: 1 ; Batch Number: 700; Train Loss: 0.6515 ; Valid Loss: 0.6027 ; Valid Accuracy: 0.6661\n",
            "Epoch: 1 ; Batch Number: 800; Train Loss: 0.5797 ; Valid Loss: 0.5912 ; Valid Accuracy: 0.6784\n",
            "Epoch: 1 ; Batch Number: 900; Train Loss: 0.5161 ; Valid Loss: 0.5851 ; Valid Accuracy: 0.6734\n",
            "Epoch: 1 ; Batch Number: 1000; Train Loss: 0.6860 ; Valid Loss: 0.5785 ; Valid Accuracy: 0.6893\n",
            "Epoch: 1 ; Batch Number: 1100; Train Loss: 0.5490 ; Valid Loss: 0.5712 ; Valid Accuracy: 0.6899\n",
            "Epoch: 1 ; Batch Number: 1200; Train Loss: 0.5883 ; Valid Loss: 0.5636 ; Valid Accuracy: 0.6954\n",
            "Epoch: 2 ; Batch Number: 1300; Train Loss: 0.3649 ; Valid Loss: 0.5854 ; Valid Accuracy: 0.6989\n",
            "Epoch: 2 ; Batch Number: 1400; Train Loss: 0.2983 ; Valid Loss: 0.5696 ; Valid Accuracy: 0.7040\n",
            "Epoch: 2 ; Batch Number: 1500; Train Loss: 0.4210 ; Valid Loss: 0.5622 ; Valid Accuracy: 0.7065\n",
            "Epoch: 2 ; Batch Number: 1600; Train Loss: 0.4113 ; Valid Loss: 0.5575 ; Valid Accuracy: 0.7027\n",
            "Epoch: 2 ; Batch Number: 1700; Train Loss: 0.4552 ; Valid Loss: 0.5602 ; Valid Accuracy: 0.7120\n",
            "Epoch: 2 ; Batch Number: 1800; Train Loss: 0.5542 ; Valid Loss: 0.5464 ; Valid Accuracy: 0.7134\n",
            "Epoch: 2 ; Batch Number: 1900; Train Loss: 0.5150 ; Valid Loss: 0.5555 ; Valid Accuracy: 0.7166\n",
            "Epoch: 2 ; Batch Number: 2000; Train Loss: 0.4251 ; Valid Loss: 0.5540 ; Valid Accuracy: 0.7159\n",
            "Epoch: 2 ; Batch Number: 2100; Train Loss: 0.4181 ; Valid Loss: 0.5483 ; Valid Accuracy: 0.7192\n",
            "Epoch: 2 ; Batch Number: 2200; Train Loss: 0.4761 ; Valid Loss: 0.5494 ; Valid Accuracy: 0.7244\n",
            "Epoch: 2 ; Batch Number: 2300; Train Loss: 0.4688 ; Valid Loss: 0.5524 ; Valid Accuracy: 0.7240\n",
            "Epoch: 2 ; Batch Number: 2400; Train Loss: 0.5437 ; Valid Loss: 0.5464 ; Valid Accuracy: 0.7221\n",
            "Epoch: 2 ; Batch Number: 2500; Train Loss: 0.5243 ; Valid Loss: 0.5437 ; Valid Accuracy: 0.7164\n",
            "Epoch: 3 ; Batch Number: 2600; Train Loss: 0.3159 ; Valid Loss: 0.5662 ; Valid Accuracy: 0.7229\n",
            "Epoch: 3 ; Batch Number: 2700; Train Loss: 0.4817 ; Valid Loss: 0.5588 ; Valid Accuracy: 0.7236\n",
            "Epoch: 3 ; Batch Number: 2800; Train Loss: 0.4696 ; Valid Loss: 0.5734 ; Valid Accuracy: 0.7262\n",
            "Epoch: 3 ; Batch Number: 2900; Train Loss: 0.4404 ; Valid Loss: 0.5586 ; Valid Accuracy: 0.7262\n",
            "Epoch: 3 ; Batch Number: 3000; Train Loss: 0.4130 ; Valid Loss: 0.5771 ; Valid Accuracy: 0.7225\n",
            "Epoch: 3 ; Batch Number: 3100; Train Loss: 0.3095 ; Valid Loss: 0.5661 ; Valid Accuracy: 0.7231\n",
            "Epoch: 3 ; Batch Number: 3200; Train Loss: 0.3972 ; Valid Loss: 0.5716 ; Valid Accuracy: 0.7264\n",
            "Epoch: 3 ; Batch Number: 3300; Train Loss: 0.4009 ; Valid Loss: 0.5732 ; Valid Accuracy: 0.7272\n",
            "Epoch: 3 ; Batch Number: 3400; Train Loss: 0.2840 ; Valid Loss: 0.5743 ; Valid Accuracy: 0.7255\n",
            "Epoch: 3 ; Batch Number: 3500; Train Loss: 0.4140 ; Valid Loss: 0.5632 ; Valid Accuracy: 0.7324\n",
            "Epoch: 3 ; Batch Number: 3600; Train Loss: 0.4212 ; Valid Loss: 0.5759 ; Valid Accuracy: 0.7202\n",
            "Epoch: 3 ; Batch Number: 3700; Train Loss: 0.4671 ; Valid Loss: 0.5614 ; Valid Accuracy: 0.7309\n",
            "Epoch: 3 ; Batch Number: 3800; Train Loss: 0.3527 ; Valid Loss: 0.5803 ; Valid Accuracy: 0.7290\n",
            "Epoch: 4 ; Batch Number: 3900; Train Loss: 0.3897 ; Valid Loss: 0.6613 ; Valid Accuracy: 0.7281\n",
            "Epoch: 4 ; Batch Number: 4000; Train Loss: 0.2600 ; Valid Loss: 0.7081 ; Valid Accuracy: 0.7264\n",
            "Epoch: 4 ; Batch Number: 4100; Train Loss: 0.3537 ; Valid Loss: 0.6907 ; Valid Accuracy: 0.7296\n",
            "Epoch: 4 ; Batch Number: 4200; Train Loss: 0.3007 ; Valid Loss: 0.6740 ; Valid Accuracy: 0.7236\n",
            "Epoch: 4 ; Batch Number: 4300; Train Loss: 0.1557 ; Valid Loss: 0.6646 ; Valid Accuracy: 0.7230\n",
            "Epoch: 4 ; Batch Number: 4400; Train Loss: 0.3471 ; Valid Loss: 0.6670 ; Valid Accuracy: 0.7259\n",
            "Epoch: 4 ; Batch Number: 4500; Train Loss: 0.3380 ; Valid Loss: 0.6470 ; Valid Accuracy: 0.7254\n",
            "Epoch: 4 ; Batch Number: 4600; Train Loss: 0.3002 ; Valid Loss: 0.6621 ; Valid Accuracy: 0.7266\n",
            "Epoch: 4 ; Batch Number: 4700; Train Loss: 0.2368 ; Valid Loss: 0.6553 ; Valid Accuracy: 0.7259\n",
            "Epoch: 4 ; Batch Number: 4800; Train Loss: 0.2303 ; Valid Loss: 0.6518 ; Valid Accuracy: 0.7281\n",
            "Epoch: 4 ; Batch Number: 4900; Train Loss: 0.2209 ; Valid Loss: 0.6349 ; Valid Accuracy: 0.7254\n",
            "Epoch: 4 ; Batch Number: 5000; Train Loss: 0.2120 ; Valid Loss: 0.6612 ; Valid Accuracy: 0.7295\n",
            "Epoch: 4 ; Batch Number: 5100; Train Loss: 0.2539 ; Valid Loss: 0.6707 ; Valid Accuracy: 0.7294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNNThCsgpe-o",
        "colab_type": "text"
      },
      "source": [
        "### Предсказание окраски по тексту"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HxNOKY5qCmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_text(test_review):\n",
        "    test_review = test_review.lower()\n",
        "    punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "    \n",
        "    new_text = []\n",
        "    for word in test_words:\n",
        "        if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n",
        "            new_text.append(word)\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in new_text])\n",
        "\n",
        "    return test_ints"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN7jtCPrqKX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_review, sequence_length=30):\n",
        "    model.eval()\n",
        "    test_ints = tokenize_text(test_review)\n",
        "    seq_length=sequence_length\n",
        "    features = add_pads(test_ints, seq_length)\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    batch_size = feature_tensor.size(0)\n",
        "    h = model.init_hidden_state(batch_size)\n",
        "    if(train_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    output, h = model(feature_tensor, h)\n",
        "    \n",
        "    pred = torch.round(output.squeeze()) \n",
        "    print('Вероятность положительного ответа {:.6f}'.format(output.item()))\n",
        "    \n",
        "    if(pred.item()==1):\n",
        "        print(\"Позитивное сообщение\")\n",
        "    else:\n",
        "        print(\"Негативное сообщение\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWH06tObqP21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1f479437-50e5-45e7-974f-8439903e6126"
      },
      "source": [
        "seq_length = 30 \n",
        "test_review = \"Как ты могла со мной так мерзко поступить? Я ухожу!\"\n",
        "predict(model, test_review, seq_length)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вероятность положительного ответа 0.007588\n",
            "Негативное сообщение\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}